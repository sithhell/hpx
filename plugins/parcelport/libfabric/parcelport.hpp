//  Copyright (c) 2015-2016 John Biddiscombe
//
//  Distributed under the Boost Software License, Version 1.0. (See accompanying
//  file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)

#ifndef HPX_PARCELSET_POLICIES_LIBFABRIC_PARCELPORT_HPP
#define HPX_PARCELSET_POLICIES_LIBFABRIC_PARCELPORT_HPP

// config
#include <hpx/config.hpp>
// util
#include <hpx/util/command_line_handling.hpp>
#include <hpx/util/runtime_configuration.hpp>
#include <hpx/util/high_resolution_timer.hpp>
#include <hpx/lcos/local/condition_variable.hpp>
#include <hpx/runtime/threads/thread_data.hpp>

// The memory pool specialization need to be pulled in before encode_parcels
#include <hpx/runtime.hpp>
#include <hpx/runtime/parcelset/parcelport.hpp>
#include <hpx/runtime/parcelset/parcel_buffer.hpp>
#include <hpx/runtime/parcelset/encode_parcels.hpp>
#include <hpx/runtime/parcelset/decode_parcels.hpp>
#include <hpx/plugins/parcelport_factory.hpp>
#include <hpx/runtime/parcelset/parcelport_impl.hpp>
//
#include <hpx/util/debug/thread_stacktrace.hpp>
//
#include <boost/asio/ip/host_name.hpp>
//
// This header is generated by CMake and contains a number of configurable
// setting that affect the parcelport. It needs to be #included before
// other files that are part of the parcelport
#include <hpx/config/parcelport_defines.hpp>

// --------------------------------------------------------------------
// Controls whether we are allowed to suspend threads that are sending
// when we have maxed out the number of sends we can handle
#define HPX_PARCELPORT_LIBFABRIC_SUSPEND_WAKE  (HPX_PARCELPORT_LIBFABRIC_THROTTLE_SENDS/2)


// --------------------------------------------------------------------
// Enable the use of boost small_vector for certain short lived storage
// elements within the parcelport. This can reduce some memory allocations
#define HPX_PARCELPORT_LIBFABRIC_USE_SMALL_VECTOR    true

#define HPX_PARCELPORT_LIBFABRIC_IMM_UNSUPPORTED 1

// --------------------------------------------------------------------
#include <plugins/parcelport/unordered_map.hpp>
#include <plugins/parcelport/libfabric/header.hpp>
#include <plugins/parcelport/libfabric/locality.hpp>

#include <plugins/parcelport/libfabric/sender.hpp>
#include <plugins/parcelport/libfabric/connection_handler.hpp>
//#include <plugins/parcelport/libfabric/pinned_memory_vector.hpp>
#include <plugins/parcelport/libfabric/performance_counter.hpp>
//
// rdma libfabric utilities
#include <plugins/parcelport/parcelport_logging.hpp>
#include <plugins/parcelport/libfabric/libfabric_memory_region.hpp>
#include <plugins/parcelport/libfabric/rdma_locks.hpp>
#include <plugins/parcelport/libfabric/rdma_memory_pool.hpp>
#include <plugins/parcelport/libfabric/libfabric_controller.hpp>

//
#if HPX_PARCELPORT_LIBFABRIC_USE_SMALL_VECTOR
# include <boost/container/small_vector.hpp>
#endif
//
#include <unordered_map>
#include <memory>
#include <mutex>
#include <sstream>
#include <cstddef>
#include <cstdint>
#include <cstring>
#include <iostream>
#include <list>
#include <string>
#include <utility>
#include <vector>

using namespace hpx::parcelset::policies;

namespace hpx {
namespace parcelset {
namespace policies {
namespace libfabric
{
    // --------------------------------------------------------------------
    // Simple atomic counter we use for tags
    // When a parcel is sent to a remote locality, it may need to pull zero copy
    // chunks from us. We keep the chunks until the remote locality sends a zero byte
    // message with the tag we gave them and then we know it is safe to release the
    // memory back to the pool.
    // The tags can have a short lifetime, but must be unique, so we encode the ip
    // address with a counter to generate tags per destination.
    // The tag is sent in immediate data so must be 32bits only : Note that the tag
    // only has a lifetime of the unprocessed parcel, so it can be reused as soon as
    // the parcel has been completed and therefore a 16bit count is sufficient as we
    // only keep a few parcels per locality in flight at a time
    // --------------------------------------------------------------------
    struct tag_provider {
        tag_provider() : next_tag_(1) {}

        uint32_t next(uint32_t fi_addr)
        {
            // @TODO track wrap around and collisions (how?)
            return (next_tag_++ & 0x0000FFFF) + ((fi_addr << 16) & 0xFFFF0000);
        }

        // using 16 bits currently.
        std::atomic<uint32_t> next_tag_;
    };

    // --------------------------------------------------------------------
    // parcelport, the implementation of the parcelport itself
    // --------------------------------------------------------------------
    struct HPX_EXPORT parcelport : public parcelport_impl<parcelport>
    {
    private:
        typedef parcelport_impl<parcelport> base_type;

    public:

        // These are the types used in the parcelport for locking etc
        // Note that spinlock is the only supported mutex that works on HPX+OS threads
        // and condition_variable_any can be used across HPX/OS threads
        typedef hpx::lcos::local::spinlock                               mutex_type;
        typedef hpx::parcelset::policies::libfabric::scoped_lock<mutex_type> scoped_lock;
        typedef hpx::parcelset::policies::libfabric::unique_lock<mutex_type> unique_lock;
        typedef hpx::lcos::local::condition_variable_any                 condition_type;

        // --------------------------------------------------------------------
        // main vars used to manage the RDMA controller and interface
        // These are called from a static function, so use static
        // --------------------------------------------------------------------
        libfabric_controller_ptr libfabric_controller_;

        // our local ip address (estimated based on fabric PP adress info)
        uint32_t ip_addr_;

        // Not currently working, we support bootstrapping, but when not enabled
        // we should be able to skip it
        bool bootstrap_enabled_;
        bool parcelport_enabled_;

        // @TODO, clean up the allocators, buffers, chunk_pool etc so that there is a
        // more consistent reuse of classes/types.
        // The use of pointer allocators etc is a dreadful hack and needs reworking

        typedef header<HPX_PARCELPORT_LIBFABRIC_MESSAGE_HEADER_SIZE> header_type;
        static constexpr unsigned int header_size = header_type::header_block_size;
        typedef rdma_memory_pool                                   memory_pool_type;
        typedef pinned_memory_vector<char, header_size>            snd_data_type;
        typedef parcel_buffer<snd_data_type>                       snd_buffer_type;

        // when terminating the parcelport, this is used to restrict access
        mutex_type  stop_mutex;

        boost::lockfree::stack<
            sender*,
            boost::lockfree::capacity<HPX_PARCELPORT_LIBFABRIC_THROTTLE_SENDS>,
            boost::lockfree::fixed_sized<true>
        > senders_;


        // These are counters that are used for flow control so that we can throttle
        // send tasks when too many messages have been posted.
        std::atomic<unsigned int> active_send_count_;
        // Used to help with shutdown
        std::atomic<bool>         stopped_;

        memory_pool_type*         chunk_pool_;

        // performance_counters::parcels::gatherer& parcels_sent_;

        // a count of all receives, for debugging/performance measurement
        performance_counter<unsigned int> sends_posted;
        performance_counter<unsigned int> handled_receives;
        performance_counter<unsigned int> completions_handled;
        performance_counter<unsigned int> total_reads;

        // --------------------------------------------------------------------
        // Constructor : mostly just initializes the superclass with 'here'
        // --------------------------------------------------------------------
        parcelport(util::runtime_configuration const& ini,
            util::function_nonser<void(std::size_t, char const*)> const& on_start_thread,
            util::function_nonser<void()> const& on_stop_thread);

        // Start the handling of connections.
        bool do_run();

//         std::shared_ptr<sender_connection> singleton_connection;

        // --------------------------------------------------------------------
        // return a sender_connection object back to the parcelport_impl
        // this is used by the send_immediate version of parcelport_impl
        // --------------------------------------------------------------------
        sender* get_connection(
            parcelset::locality const& dest, fi_addr_t &fi_addr);

        // --------------------------------------------------------------------
        // return a sender object back to the parcelport_impl
        // this is for compatibility with non send_immediate operation
        // --------------------------------------------------------------------
        std::shared_ptr<sender> create_connection(
            parcelset::locality const& dest, error_code& ec);

        ~parcelport();

        /// Should not be used any more as parcelport_impl handles this?
        bool can_bootstrap() const;

        /// Return the name of this locality
        std::string get_locality_name() const;

        parcelset::locality agas_locality(util::runtime_configuration const & ini) const;

        parcelset::locality create_locality() const;

        static void suspended_task_debug(const std::string &match);

        void do_stop();

        // --------------------------------------------------------------------
        bool can_send_immediate();

        // --------------------------------------------------------------------
        template <typename Handler>
        bool async_write(Handler && handler,
            sender *sender, fi_addr_t addr,
            snd_buffer_type &buffer);

        // --------------------------------------------------------------------
        // This is called to poll for completions and handle all incoming messages
        // as well as complete outgoing messages.
        // --------------------------------------------------------------------
        // Background work
        //
        // This is called whenever the main thread scheduler is idling,
        // is used to poll for events, messages on the libfabric connection
        // --------------------------------------------------------------------
        bool background_work(std::size_t num_thread);
    };
}}}}

namespace hpx {
namespace traits {
// Inject additional configuration data into the factory registry for this
// type. This information ends up in the system wide configuration database
// under the plugin specific section:
//
//      [hpx.parcel.libfabric]
//      ...
//      priority = 100
//
template<>
struct plugin_config_data<hpx::parcelset::policies::libfabric::parcelport> {
    static char const* priority() {
        FUNC_START_DEBUG_MSG;
        static int log_init = false;
        if (!log_init) {
#if defined(HPX_PARCELPORT_LIBFABRIC_HAVE_LOGGING) || \
    defined(HPX_PARCELPORT_LIBFABRIC_HAVE_DEV_MODE)
            boost::log::add_console_log(
            std::clog,
            // This makes the sink to write log records that look like this:
            // 1: <normal> A normal severity message
            // 2: <error> An error severity message
            boost::log::keywords::format =
                (
                    boost::log::expressions::stream
                    // << (boost::format("%05d") % expr::attr< unsigned int >("LineID"))
                    << boost::log::expressions::attr< unsigned int >("LineID")
                    << ": <" << boost::log::trivial::severity
                    << "> " << boost::log::expressions::smessage
                )
            );
            boost::log::add_common_attributes();
#endif
            log_init = true;
        }
        FUNC_END_DEBUG_MSG;
        return "10000";
    }

    // This is used to initialize your parcelport,
    // for example check for availability of devices etc.
    static void init(int *argc, char ***argv, util::command_line_handling &cfg) {
        FUNC_START_DEBUG_MSG;

        FUNC_END_DEBUG_MSG;
    }

    static char const* call()
    {
        FUNC_START_DEBUG_MSG;
        FUNC_END_DEBUG_MSG;
        // @TODO : check which of these are obsolete after recent changes
        return
        "zero_copy_optimization = 1\n"
        "provider = ${HPX_PARCELPORT_LIBFABRIC_PROVIDER:"
                HPX_PARCELPORT_LIBFABRIC_PROVIDER "}\n"
        "domain = ${HPX_PARCELPORT_LIBFABRIC_DOMAIN:"
                HPX_PARCELPORT_LIBFABRIC_DOMAIN "}\n"
        "endpoint = ${HPX_PARCELPORT_LIBFABRIC_ENDPOINT:"
                HPX_PARCELPORT_LIBFABRIC_ENDPOINT "}\n"
        ;
    }
};
}}

/*
            libfabric_controller_->for_each_client(
                [](std::pair<uint32_t, libfabric_endpoint_ptr> clientpair)
                {
                libfabric_endpoint* client = clientpair.second.get();
                LOG_TIMED_INIT(clientlog);
                LOG_TIMED_MSG(clientlog, DEVEL, 0.1,
                    "internal reported, \n"
                    << "recv " << decnumber(client->get_total_posted_recv_count()) << "\n"
                    << "send " << decnumber(client->get_total_posted_send_count()) << "\n"
                    << "read " << decnumber(client->get_total_posted_read_count()) << "\n"
                );
                }
            );

            LOG_TIMED_INIT(background);
            LOG_TIMED_MSG(background, DEVEL, 0.1,
                "PP reported\n"
                << "actv " << decnumber(active_send_count_) << "\n"
                << "recv " << decnumber(handled_receives) << "\n"
                << "send " << decnumber(sends_posted) << "\n"
                << "read " << decnumber(total_reads) << "\n"
                << "Total completions " << decnumber(completions_handled)
                << decnumber(sends_posted+handled_receives+total_reads));
*/

#endif
